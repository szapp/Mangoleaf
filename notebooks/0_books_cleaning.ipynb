{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning\n",
    "\n",
    "Using the dataset [arashnic/book-recommendation-dataset](https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset), initial data cleaning involves removing mal-formatted rows and removing the implicit ratings. Only explicit ratings in the range from 1 to 10 are considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = (\n",
    "    \"https://www.kaggle.com/api/v1/datasets/download/\"\n",
    "    \"arashnic/book-recommendation-dataset?datasetVersionNumber=3\"\n",
    ")\n",
    "zip_path = urlretrieve(url)[0]\n",
    "with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
    "\n",
    "    with zf.open(\"Books.csv\") as f:\n",
    "        books = pd.read_csv(f)\n",
    "\n",
    "    with zf.open(\"Ratings.csv\") as f:\n",
    "        ratings = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any books to removem, remove from \"books\" and \"ratings\"\n",
    "removed_isbn = []\n",
    "\n",
    "# Three book entries are mal-formatted, and some authors and publishers are missing\n",
    "removed_isbn += books[books[\"Year-Of-Publication\"].str.isnumeric() == False].ISBN.to_list()\n",
    "removed_isbn += books[(books[\"Year-Of-Publication\"] == 0) |\n",
    "                      (books[\"Year-Of-Publication\"] == \"0\")].ISBN.to_list()\n",
    "removed_isbn += books[books[\"Book-Author\"].isna()].ISBN.to_list()\n",
    "removed_isbn += books[books[\"Publisher\"].isna()].ISBN.to_list()\n",
    "\n",
    "# Remove the selected books in both \"books\" and \"ratings\"\n",
    "books = books[~books[\"ISBN\"].isin(removed_isbn)]\n",
    "ratings = ratings[~ratings[\"ISBN\"].isin(removed_isbn)]\n",
    "\n",
    "# Implicit ratings are marked as zero. We are not using implicit ratings here for now\n",
    "ratings = ratings.drop(ratings[ratings[\"Book-Rating\"] == 0].index)\n",
    "\n",
    "# Remove any books that received no ratings\n",
    "books = books[books[\"ISBN\"].isin(ratings[\"ISBN\"])]\n",
    "\n",
    "# Remove second editions (TODO: Keep the most popular edition or merge the ratings)\n",
    "books = books.drop_duplicates(subset=[\"Book-Title\", \"Book-Author\"])\n",
    "\n",
    "# Remove any ratings to non-existing books\n",
    "ratings = ratings[ratings[\"ISBN\"].isin(books[\"ISBN\"])]\n",
    "\n",
    "# Convert year to integer\n",
    "books[\"Year-Of-Publication\"] = pd.to_numeric(books[\"Year-Of-Publication\"])\n",
    "\n",
    "# # Turn year 0 to missing value\n",
    "# books.loc[books[\"Year-Of-Publication\"] == 0, \"Year-Of-Publication\"] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce the dataset\n",
    "\n",
    "The dataset is too large with nearly 200k books.\n",
    "Creating a user-item-matrix is not feasible for a lightweight Streamlit app in the end.\n",
    "Since there are a lot of users who gave only one rating and books that only received one rating, I will remove these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining ratings: 29573\n",
      "Remaining users: 1382\n",
      "Remaining books: 1508, 1508\n"
     ]
    }
   ],
   "source": [
    "users_to_drop = [1]\n",
    "books_to_drop = [1]\n",
    "\n",
    "# Because dropping users influces the number of ratings per book,\n",
    "# we need to iterate until no more users or books are dropped\n",
    "while len(users_to_drop) != 0 and len(books_to_drop) != 0:\n",
    "\n",
    "    # Find users that gave less than five ratings\n",
    "    few_rating_users = ratings[\"User-ID\"].value_counts() < 10\n",
    "    users_to_drop = few_rating_users[few_rating_users].index\n",
    "\n",
    "    # Find books that received less than five ratings\n",
    "    few_rated_books = ratings[\"ISBN\"].value_counts() < 10\n",
    "    books_to_drop = few_rated_books[few_rated_books].index\n",
    "\n",
    "    # Remove them from the ratings\n",
    "    ratings = ratings[~ratings[\"User-ID\"].isin(users_to_drop)]\n",
    "    ratings = ratings[~ratings[\"ISBN\"].isin(books_to_drop)]\n",
    "    books = books[books[\"ISBN\"].isin(ratings[\"ISBN\"])]\n",
    "\n",
    "# Report remaining rating size\n",
    "print(f\"Remaining ratings: {ratings.shape[0]}\")\n",
    "print(f\"Remaining users: {ratings['User-ID'].nunique()}\")\n",
    "print(f\"Remaining books: {ratings['ISBN'].nunique()}, {books['ISBN'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the ratings\n",
    "\n",
    "The Streamlit feedback rating widget spans a range from 1 to 5 stars. So we will scale the rating to the same range.\n",
    "\n",
    "Because that range is compressed and may lose information, we will use power transform to diversify the ratings. Note that this results in ratings that are no longer accurate, but it is a good demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings[\"Book-Rating\"] = preprocessing.power_transform(ratings[[\"Book-Rating\"]])\n",
    "ratings[\"Book-Rating\"] = preprocessing.minmax_scale(ratings[[\"Book-Rating\"]], (1, 5))\n",
    "ratings[\"Book-Rating\"] = ratings[\"Book-Rating\"].round().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.to_csv(\"../data/books/clean/books.csv\", index=False)\n",
    "ratings.to_csv(\"../data/books/clean/ratings.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mangoleaf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
