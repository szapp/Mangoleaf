{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-Based Recommender\n",
    "\n",
    "Using the dataset [arashnic/book-recommendation-dataset](https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset), the function `user_based_recommender` returns the `n` most popular books recommended to the user `user_id`.\n",
    "\n",
    "The recommender is implemented using the Suprise library.\n",
    "\n",
    "Initial data cleaning involves removing mal-formatted rows and removing the implicit ratings.\n",
    "Only explicit ratings in the range from 1 to 10 are considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import pandas as pd\n",
    "from surprise import SVD, Dataset, KNNBaseline, KNNBasic, KNNWithZScore, Reader, SVDpp\n",
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\settings\\AppData\\Local\\Temp\\ipykernel_13676\\2869137190.py:9: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books = pd.read_csv(f)\n"
     ]
    }
   ],
   "source": [
    "url = (\n",
    "    \"https://www.kaggle.com/api/v1/datasets/download/\"\n",
    "    \"arashnic/book-recommendation-dataset?datasetVersionNumber=3\"\n",
    ")\n",
    "zip_path = urlretrieve(url)[0]\n",
    "with zipfile.ZipFile(zip_path, \"r\") as zf:\n",
    "\n",
    "    with zf.open(\"Books.csv\") as f:\n",
    "        books = pd.read_csv(f)\n",
    "\n",
    "    with zf.open(\"Ratings.csv\") as f:\n",
    "        ratings = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any books to removem, remove from \"books\" and \"ratings\"\n",
    "removed_isbn = []\n",
    "\n",
    "# Three book entries are mal-formatted, and some authors and publishers are missing\n",
    "removed_isbn += books[books[\"Year-Of-Publication\"].str.isnumeric() == False].ISBN.to_list()\n",
    "removed_isbn += books[books[\"Book-Author\"].isna()].ISBN.to_list()\n",
    "removed_isbn += books[books[\"Publisher\"].isna()].ISBN.to_list()\n",
    "\n",
    "# Remove the selected books in both \"books\" and \"ratings\"\n",
    "books = books[~books[\"ISBN\"].isin(removed_isbn)]\n",
    "ratings = ratings[~ratings[\"ISBN\"].isin(removed_isbn)]\n",
    "\n",
    "# Implicit ratings are marked as zero. We are not using implicit ratings here for now\n",
    "ratings = ratings.drop(ratings[ratings[\"Book-Rating\"] == 0].index)\n",
    "\n",
    "# Remove any books that received no ratings\n",
    "books = books[books[\"ISBN\"].isin(ratings[\"ISBN\"])]\n",
    "\n",
    "# Remove second editions (TODO: Keep the most popular edition or merge the ratings)\n",
    "books = books.drop_duplicates(subset=[\"Book-Title\", \"Book-Author\"])\n",
    "\n",
    "# Remove any ratings to non-existing books\n",
    "ratings = ratings[ratings[\"ISBN\"].isin(books[\"ISBN\"])]\n",
    "\n",
    "# Convert year to integer\n",
    "books[\"Year-Of-Publication\"] = pd.to_numeric(books[\"Year-Of-Publication\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce the dataset\n",
    "\n",
    "The dataset is too large with nearly 200k books.\n",
    "Creating a user-item-matrix is not feasible for a lightweight Streamlit app in the end.\n",
    "Since there are a lot of users who gave only one rating and books that only received one rating, I will remove these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining ratings: 144055\n",
      "Remaining users: 9689\n",
      "Remaining books: 13743, 13743\n"
     ]
    }
   ],
   "source": [
    "users_to_drop = [1]\n",
    "books_to_drop = [1]\n",
    "\n",
    "# Because dropping users influces the number of ratings per book,\n",
    "# we need to iterate until no more users or books are dropped\n",
    "while len(users_to_drop) != 0 and len(books_to_drop) != 0:\n",
    "\n",
    "    # Find users that gave less than five ratings\n",
    "    few_rating_users = ratings[\"User-ID\"].value_counts() < 4\n",
    "    users_to_drop = few_rating_users[few_rating_users].index\n",
    "\n",
    "    # Find books that received less than five ratings\n",
    "    few_rated_books = ratings[\"ISBN\"].value_counts() < 4\n",
    "    books_to_drop = few_rated_books[few_rated_books].index\n",
    "\n",
    "    # Remove them from the ratings\n",
    "    ratings = ratings[~ratings[\"User-ID\"].isin(users_to_drop)]\n",
    "    ratings = ratings[~ratings[\"ISBN\"].isin(books_to_drop)]\n",
    "    books = books[books[\"ISBN\"].isin(ratings[\"ISBN\"])]\n",
    "\n",
    "# Report remaining rating size\n",
    "print(f\"Remaining ratings: {ratings.shape[0]}\")\n",
    "print(f\"Remaining users: {ratings['User-ID'].nunique()}\")\n",
    "print(f\"Remaining books: {ratings['ISBN'].nunique()}, {books['ISBN'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create user-based recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 10))\n",
    "data = Dataset.load_from_df(ratings, reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossvalidate different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNNBasic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = dict(\n",
    "    k=40,\n",
    "    min_k=1,\n",
    "    sim_options = dict(\n",
    "        name='cosine',\n",
    "        user_based=True,\n",
    "    )\n",
    ")\n",
    "algo = KNNBasic(**options)\n",
    "\n",
    "result = cross_validate(algo, data, measures=[\"RMSE\", \"MAE\", \"FCP\"], cv=5, n_jobs=-1)\n",
    "cv_results[\"KNNBasic\"] = (\n",
    "    result[\"test_rmse\"].mean(),\n",
    "    result[\"test_mae\"].mean(),\n",
    "    result[\"test_fcp\"].mean(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNNWithZScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = dict(\n",
    "    k=40,\n",
    "    min_k=1,\n",
    "    sim_options = dict(\n",
    "        name='cosine',\n",
    "        user_based=True,\n",
    "    )\n",
    ")\n",
    "algo = KNNWithZScore(**options)\n",
    "\n",
    "result = cross_validate(algo, data, measures=[\"RMSE\", \"MAE\", \"FCP\"], cv=5, n_jobs=-1)\n",
    "cv_results[\"KNNWithZScore\"] = (\n",
    "    result[\"test_rmse\"].mean(),\n",
    "    result[\"test_mae\"].mean(),\n",
    "    result[\"test_fcp\"].mean(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNNBaseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = dict(\n",
    "    k=40,\n",
    "    min_k=1,\n",
    "    sim_options = dict(\n",
    "        name='cosine',\n",
    "        user_based=True,\n",
    "    )\n",
    "    bsl_options = dict(\n",
    "        method=\"als\",\n",
    "        reg_i=10,\n",
    "        reg_u=15,\n",
    "        n_epochs=10,\n",
    "    )\n",
    ")\n",
    "algo = KNNBaseline(**options)\n",
    "\n",
    "result = cross_validate(algo, data, measures=[\"RMSE\", \"MAE\", \"FCP\"], cv=5, n_jobs=-1)\n",
    "cv_results[\"KNNBaseline\"] = (\n",
    "    result[\"test_rmse\"].mean(),\n",
    "    result[\"test_mae\"].mean(),\n",
    "    result[\"test_fcp\"].mean(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = dict(\n",
    "    n_factors=100,  # Number of factors\n",
    "    n_epochs=20,  # Number of iteration of the SGD procedure\n",
    "    biased=True,  # Whether to use baselines (or biases)\n",
    "    init_mean=0,  # Mean of normal distribution for factor vectors initialization\n",
    "    init_std_dev=0.1,  # S.D. of normal distribution for factor vectors initialization\n",
    "    lr_all=0.005,  # Learning rate for all parameters\n",
    "    reg_all=0.02,  # Regularization term for all parameters\n",
    "    lr_bu=None,  # Learning rate. Takes precedence over lr_all if set\n",
    "    lr_bi=None,  # Learning rate. Takes precedence over lr_all if set\n",
    "    lr_pu=None,  # Learning rate. Takes precedence over lr_all if set\n",
    "    lr_qi=None,  # Learning rate. Takes precedence over lr_all if set\n",
    "    reg_bu=None,  # Regularization term. Takes precedence over reg_all if set\n",
    "    reg_bi=None,  # Regularization term. Takes precedence over reg_all if set\n",
    "    reg_pu=None,  # Regularization term. Takes precedence over reg_all if set\n",
    "    reg_qi=None,  # Regularization term. Takes precedence over reg_all if set\n",
    ")\n",
    "algo = SVD(**options, random_state=123)\n",
    "\n",
    "result = cross_validate(algo, data, measures=[\"RMSE\", \"MAE\", \"FCP\"], cv=5, n_jobs=-1)\n",
    "cv_results[\"SVD\"] = (\n",
    "    result[\"test_rmse\"].mean(),\n",
    "    result[\"test_mae\"].mean(),\n",
    "    result[\"test_fcp\"].mean(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = dict(\n",
    "    n_factors=100,  # Number of factors\n",
    "    n_epochs=20,  # Number of iteration of the SGD procedure\n",
    "    cache_ratings=True,  # Whether or not to cache ratings\n",
    "    init_mean=0,  # Mean of normal distribution for factor vectors initialization\n",
    "    init_std_dev=0.1,  # S.D. of normal distribution for factor vectors initialization\n",
    "    lr_all=0.005,  # Learning rate for all parameters\n",
    "    reg_all=0.02,  # Regularization term for all parameters\n",
    "    lr_bu=None,  # Learning rate. Takes precedence over lr_all if set\n",
    "    lr_bi=None,  # Learning rate. Takes precedence over lr_all if set\n",
    "    lr_pu=None,  # Learning rate. Takes precedence over lr_all if set\n",
    "    lr_qi=None,  # Learning rate. Takes precedence over lr_all if set\n",
    "    lr_yj=None,  # Learning rate. Takes precedence over lr_all if set\n",
    "    reg_bu=None,  # Regularization term. Takes precedence over reg_all if set\n",
    "    reg_bi=None,  # Regularization term. Takes precedence over reg_all if set\n",
    "    reg_pu=None,  # Regularization term. Takes precedence over reg_all if set\n",
    "    reg_qi=None,  # Regularization term. Takes precedence over reg_all if set\n",
    "    reg_yj=None,  # Regularization term. Takes precedence over reg_all if set\n",
    ")\n",
    "algo = SVDpp(**options, random_state=123)\n",
    "\n",
    "result = cross_validate(algo, data, measures=[\"RMSE\", \"MAE\", \"FCP\"], cv=5, n_jobs=-1)\n",
    "cv_results[\"SVDpp\"] = (\n",
    "    result[\"test_rmse\"].mean(),\n",
    "    result[\"test_mae\"].mean(),\n",
    "    result[\"test_fcp\"].mean(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>fcp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNNBasic</th>\n",
       "      <td>1.963572</td>\n",
       "      <td>1.521722</td>\n",
       "      <td>0.580354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithZScore</th>\n",
       "      <td>1.733412</td>\n",
       "      <td>1.289334</td>\n",
       "      <td>0.581157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBaseline</th>\n",
       "      <td>1.755636</td>\n",
       "      <td>1.340416</td>\n",
       "      <td>0.545017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>1.571060</td>\n",
       "      <td>1.210091</td>\n",
       "      <td>0.517932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVDpp</th>\n",
       "      <td>1.584473</td>\n",
       "      <td>1.221660</td>\n",
       "      <td>0.516004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   rmse       mae       fcp\n",
       "KNNBasic       1.963572  1.521722  0.580354\n",
       "KNNWithZScore  1.733412  1.289334  0.581157\n",
       "KNNBaseline    1.755636  1.340416  0.545017\n",
       "SVD            1.571060  1.210091  0.517932\n",
       "SVDpp          1.584473  1.221660  0.516004"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv_results, index=['rmse', 'mae', 'fcp']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "options = dict(\n",
    "    k=40,\n",
    "    min_k=1,\n",
    "    sim_options = dict(\n",
    "        name='cosine',\n",
    "        user_based=True,\n",
    "    )\n",
    ")\n",
    "algo = KNNWithZScore(**options)\n",
    "\n",
    "full_train = data.build_full_trainset()\n",
    "algo.fit(full_train)\n",
    "\n",
    "testset = full_train.build_anti_testset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main function is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_based_recommender(user_id, n):\n",
    "    \"\"\"\n",
    "    Recommends the n best matching books for a giving user\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    user_id : int\n",
    "        User ID for which to get recommendations\n",
    "    n : int\n",
    "        Number of books to recommend\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame containing the top n book recommendations for the specified user_id\n",
    "    \"\"\"\n",
    "    # Filter the testset to include only rows with the specified user_id\n",
    "    filtered_testset = [row for row in testset if row[0] == user_id]\n",
    "\n",
    "    # Make predictions on the filtered testset\n",
    "    predictions = algo.test(filtered_testset)\n",
    "\n",
    "    # Get the top n predictions based on the estimated ratings ('est')\n",
    "    top_n_predictions_df = pd.DataFrame(predictions).nlargest(n, 'est')\n",
    "\n",
    "    # Creating a DataFrame from the top_n with columns 'ISBN' and 'estimated_rating'\n",
    "    reduced_top_n_df = top_n_predictions_df.loc[:, [\"iid\", \"est\"]].rename(\n",
    "        columns=dict(iid=\"ISBN\", est=\"estimated_rating\")\n",
    "    )\n",
    "\n",
    "    # Merging the 2 created DataFrames based on 'ISBN', retaining only the matching rows\n",
    "    merged_df = reduced_top_n_df.merge(books, how=\"left\")\n",
    "\n",
    "    # Selecting specific columns from the merged DataFrame to include in the final result\n",
    "    final_df = merged_df[[\n",
    "        \"ISBN\",\n",
    "        \"Book-Title\",\n",
    "        \"Book-Author\",\n",
    "        \"Year-Of-Publication\",\n",
    "    ]]\n",
    "    \n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a user that has a good record of rating books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114368"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_count = ratings.drop(columns=\"ISBN\")\n",
    "rating_count = rating_count.groupby(\"User-ID\")[\"Book-Rating\"].agg([\"count\"]).reset_index()\n",
    "rating_count.nlargest(10, \"count\").iloc[4, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage to obtain the top 10 most recommended books for a user in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>843760494X</td>\n",
       "      <td>Cien AÃ±os de Soledad</td>\n",
       "      <td>Gabriel GarcÃ­a MÃ¡rquez</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0439176824</td>\n",
       "      <td>The Fall (The Seventh Tower, Book 1)</td>\n",
       "      <td>Garth Nix</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0440228352</td>\n",
       "      <td>Whirligig (Laurel Leaf Books)</td>\n",
       "      <td>Paul Fleischman</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0140283641</td>\n",
       "      <td>Kits Law</td>\n",
       "      <td>Donna Morrissey</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0689831404</td>\n",
       "      <td>The Wind in the Willows (Aladdin Classics)</td>\n",
       "      <td>Kenneth Grahame</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0330328743</td>\n",
       "      <td>Butcher Boy</td>\n",
       "      <td>Patrick Mccabe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0345419081</td>\n",
       "      <td>The Eight</td>\n",
       "      <td>KATHERINE NEVILLE</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>060961004X</td>\n",
       "      <td>Eat Cake : A Novel</td>\n",
       "      <td>JEANNE RAY</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0152099905</td>\n",
       "      <td>The Borrowers</td>\n",
       "      <td>Mary Norton</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0553213113</td>\n",
       "      <td>Moby-Dick</td>\n",
       "      <td>HERMAN MELVILLE</td>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                                  Book-Title  \\\n",
       "0  843760494X                       Cien AÃ±os de Soledad   \n",
       "1  0439176824        The Fall (The Seventh Tower, Book 1)   \n",
       "2  0440228352               Whirligig (Laurel Leaf Books)   \n",
       "3  0140283641                                    Kits Law   \n",
       "4  0689831404  The Wind in the Willows (Aladdin Classics)   \n",
       "5  0330328743                                 Butcher Boy   \n",
       "6  0345419081                                   The Eight   \n",
       "7  060961004X                          Eat Cake : A Novel   \n",
       "8  0152099905                               The Borrowers   \n",
       "9  0553213113                                   Moby-Dick   \n",
       "\n",
       "                Book-Author  Year-Of-Publication  \n",
       "0  Gabriel GarcÃ­a MÃ¡rquez                 1994  \n",
       "1                 Garth Nix                 2000  \n",
       "2           Paul Fleischman                 1999  \n",
       "3           Donna Morrissey                    0  \n",
       "4           Kenneth Grahame                 1999  \n",
       "5            Patrick Mccabe                    0  \n",
       "6         KATHERINE NEVILLE                 1997  \n",
       "7                JEANNE RAY                 2003  \n",
       "8               Mary Norton                 1989  \n",
       "9           HERMAN MELVILLE                 1981  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 114368\n",
    "\n",
    "user_based_recommender(user_id, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wbs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
